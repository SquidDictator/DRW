{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a590e7a4",
   "metadata": {},
   "source": [
    "# üìò LightGBM Binary Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03748371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GaussianNoise\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "import warnings\n",
    "import optuna\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d5958",
   "metadata": {},
   "source": [
    "##  Step 1: Load Data With memory optimisation, and create dtypes for all collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24660cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "float_cols = [col for col in train_df.columns if col.startswith('X') or col == 'label']\n",
    "dtypes = {col: 'float32' for col in float_cols}\n",
    "if 'timestamp' in train_df.columns:\n",
    "    dtypes['timestamp'] = 'int64'\n",
    "if 'asset_id' in train_df.columns:\n",
    "    dtypes['asset_id'] = 'int32'\n",
    "train_df = train_df.astype(dtypes)\n",
    "test_df = pd.read_parquet(\"test.parquet\")\n",
    "test_dtypes = {col: 'float32' for col in test_df.columns if col.startswith('X')}\n",
    "if 'timestamp' in test_df.columns:\n",
    "    test_dtypes['timestamp'] = 'int64'\n",
    "if 'asset_id' in test_df.columns:\n",
    "    test_dtypes['asset_id'] = 'int32'\n",
    "if 'id' in test_df.columns:\n",
    "    test_dtypes['id'] = 'int64'\n",
    "test_df = test_df.astype(test_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1585c",
   "metadata": {},
   "source": [
    "## Step 2: Handle infinity and NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b85f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_df.fillna(train_df.median(numeric_only=True), inplace=True)\n",
    "test_df.fillna(train_df.median(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71c410",
   "metadata": {},
   "source": [
    "## Step 3: Split Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f55900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features stats:\n",
      "             bid_qty        ask_qty        buy_qty      sell_qty  \\\n",
      "count  236648.000000  236648.000000  236648.000000  236648.00000   \n",
      "mean        9.953202      10.168598     132.113877     133.37732   \n",
      "std        15.937311      16.362355     308.671787     317.79495   \n",
      "min         0.001000       0.001000       0.000000       0.00000   \n",
      "25%         2.612000       2.671000      26.524000      26.99500   \n",
      "50%         6.393000       6.534000      57.195000      58.25550   \n",
      "75%        13.073000      13.327000     128.145500     129.80625   \n",
      "max      1114.932000    1352.965000   17355.116000   17685.50300   \n",
      "\n",
      "              volume             X1             X2             X9  \\\n",
      "count  236648.000000  236648.000000  236648.000000  236648.000000   \n",
      "mean      265.491197      -0.032426      -0.000372      -0.036768   \n",
      "std       597.493751       0.912766       0.939098       0.889772   \n",
      "min         0.000000      -4.302983      -8.953153      -4.645874   \n",
      "25%        60.811000      -0.650248      -0.482887      -0.634942   \n",
      "50%       121.276000      -0.047638      -0.002534      -0.035752   \n",
      "75%       257.455500       0.570552       0.474428       0.556918   \n",
      "max     26572.521000       4.848186       9.395433       4.243651   \n",
      "\n",
      "                 X10            X11  ...           X771           X772  \\\n",
      "count  236648.000000  236648.000000  ...  236648.000000  236648.000000   \n",
      "mean       -0.000875       0.000028  ...      -0.049795       0.168578   \n",
      "std         0.889799       0.900287  ...       0.945833       1.078717   \n",
      "min       -10.652837      -8.182970  ...      -5.402806      -0.237098   \n",
      "25%        -0.435563      -0.473097  ...      -0.675319       0.046194   \n",
      "50%        -0.002955      -0.001338  ...      -0.100729       0.177237   \n",
      "75%         0.426922       0.466853  ...       0.539332       0.227746   \n",
      "max        10.454863       8.415396  ...       8.837473     275.342865   \n",
      "\n",
      "                X773           X774           X775           X776  \\\n",
      "count  236648.000000  236648.000000  236648.000000  236648.000000   \n",
      "mean       -0.001012      -0.004573      -0.004552      -0.004394   \n",
      "std         0.728395       1.001353       1.001287       1.001204   \n",
      "min        -0.185923      -0.703567      -0.717573      -0.731755   \n",
      "25%        -0.027973      -0.703345      -0.717306      -0.731417   \n",
      "50%        -0.010910      -0.702684      -0.716105      -0.725157   \n",
      "75%        -0.000684       1.366824       1.392614       1.369955   \n",
      "max       162.311005       1.522945       1.553585       1.584682   \n",
      "\n",
      "                X777           X778           X779           X780  \n",
      "count  236648.000000  236648.000000  236648.000000  236648.000000  \n",
      "mean       -0.004126      -0.004022      -0.004201      -0.004362  \n",
      "std         1.001341       1.002237       1.003859       1.005901  \n",
      "min        -0.751271      -0.807807      -0.889107      -1.071563  \n",
      "25%        -0.749833      -0.760693      -0.795364      -0.892644  \n",
      "50%        -0.692672      -0.606395      -0.620886      -0.430941  \n",
      "75%         1.320945       1.011061       0.918176       0.831780  \n",
      "max         1.627729       1.765406       1.944123       2.093233  \n",
      "\n",
      "[8 rows x 533 columns]\n",
      "\n",
      "Train target stats:\n",
      "count    236648.000000\n",
      "mean          0.034983\n",
      "std           1.013241\n",
      "min         -16.227390\n",
      "25%          -0.383167\n",
      "50%           0.014878\n",
      "75%           0.434703\n",
      "max          20.740271\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Valid features stats:\n",
      "            bid_qty       ask_qty       buy_qty      sell_qty        volume  \\\n",
      "count  26295.000000  26295.000000  26295.000000  26295.000000  26295.000000   \n",
      "mean      10.033762     10.189683    128.617916    129.436327    258.054242   \n",
      "std       16.097279     16.072159    294.389044    287.089735    555.223859   \n",
      "min        0.001000      0.001000      0.000000      0.000000      0.000000   \n",
      "25%        2.669000      2.699000     25.777000     26.923000     59.785000   \n",
      "50%        6.441000      6.512000     55.929000     57.487000    119.594000   \n",
      "75%       13.011000     13.299000    125.969500    127.761500    252.551000   \n",
      "max      583.146000    717.024000   9559.974000  11957.561000  19336.228000   \n",
      "\n",
      "                 X1            X2            X9           X10           X11  \\\n",
      "count  26295.000000  26295.000000  26295.000000  26295.000000  26295.000000   \n",
      "mean      -0.027908      0.005111     -0.028917      0.004397      0.002216   \n",
      "std        0.915412      0.946329      0.893248      0.896732      0.906108   \n",
      "min       -4.197705     -6.776554     -4.407944     -6.827725     -5.769932   \n",
      "25%       -0.652066     -0.466323     -0.629784     -0.422504     -0.466114   \n",
      "50%       -0.050869      0.003040     -0.025940     -0.000276     -0.001831   \n",
      "75%        0.579765      0.479492      0.568767      0.431679      0.467119   \n",
      "max        4.231822      6.898196      4.119435      7.867089      6.112401   \n",
      "\n",
      "       ...          X771          X772          X773          X774  \\\n",
      "count  ...  26295.000000  26295.000000  26295.000000  26295.000000   \n",
      "mean   ...     -0.042073      0.173625      0.002637     -0.002491   \n",
      "std    ...      0.955338      1.455848      1.035496      1.002868   \n",
      "min    ...     -5.272062     -0.133166     -0.116320     -0.703562   \n",
      "25%    ...     -0.681131      0.042572     -0.028100     -0.703347   \n",
      "50%    ...     -0.096173      0.176931     -0.011145     -0.702672   \n",
      "75%    ...      0.551968      0.227008     -0.000747      1.366824   \n",
      "max    ...      5.843601    156.772507    125.236588      1.522945   \n",
      "\n",
      "               X775          X776          X777          X778          X779  \\\n",
      "count  26295.000000  26295.000000  26295.000000  26295.000000  26295.000000   \n",
      "mean      -0.002481     -0.002527     -0.003195     -0.006191     -0.008566   \n",
      "std        1.002995      1.002429      1.001127      1.000019      1.000725   \n",
      "min       -0.717567     -0.731750     -0.751260     -0.807704     -0.888314   \n",
      "25%       -0.717312     -0.731423     -0.749813     -0.760214     -0.794434   \n",
      "50%       -0.716020     -0.724672     -0.690660     -0.603782     -0.618778   \n",
      "75%        1.392614      1.388335      1.320945      0.985555      0.892310   \n",
      "max        1.553585      1.584682      1.627729      1.765380      1.943664   \n",
      "\n",
      "               X780  \n",
      "count  26295.000000  \n",
      "mean      -0.009583  \n",
      "std        1.000996  \n",
      "min       -1.070037  \n",
      "25%       -0.892232  \n",
      "50%       -0.437057  \n",
      "75%        0.813493  \n",
      "max        2.092186  \n",
      "\n",
      "[8 rows x 533 columns]\n",
      "\n",
      "Valid target stats:\n",
      "count    26295.000000\n",
      "mean         0.040075\n",
      "std          1.012753\n",
      "min        -14.273204\n",
      "25%         -0.380009\n",
      "50%          0.019481\n",
      "75%          0.441300\n",
      "max         12.763814\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(columns=[\"label\"])\n",
    "y = train_df[\"label\"]\n",
    "has_timestamp = 'timestamp' in X.columns\n",
    "has_asset_id = 'asset_id' in X.columns\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "# To keep higher MI, compute temp MI and drop lower one (optional refinement)\n",
    "temp_mi = mutual_info_regression(X[to_drop], y, random_state=42)\n",
    "keep_mask = temp_mi > np.median(temp_mi)  # Keep higher MI\n",
    "to_drop = [to_drop[i] for i in range(len(to_drop)) if not keep_mask[i]]  # Drop lower\n",
    "X = X.drop(to_drop, axis=1)\n",
    "X_test_feat = test_df.drop(columns=to_drop + ['id', 'label'], errors='ignore')  # Apply to test\n",
    "\n",
    "subsample_idx = np.random.choice(X.index, size=int(0.5 * len(X)), replace=False)\n",
    "X_sub = X.loc[subsample_idx]\n",
    "y_sub = y.loc[subsample_idx]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_sub, y_sub, test_size=0.1, random_state=42)\n",
    "print(\"Train features stats:\")\n",
    "print(X_train.describe())\n",
    "print(\"\\nTrain target stats:\")\n",
    "print(y_train.describe())\n",
    "print(\"\\nValid features stats:\")\n",
    "print(X_valid.describe())\n",
    "print(\"\\nValid target stats:\")\n",
    "print(y_valid.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2f575",
   "metadata": {},
   "source": [
    "## Step 4: Preprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7311173",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)  # Use .values to avoid column name issues\n",
    "selector = VarianceThreshold(threshold=1e-4)\n",
    "X_train_reduced = selector.fit_transform(X_train_scaled)\n",
    "\n",
    "X_valid_scaled = scaler.transform(X_valid.values)\n",
    "X_valid_reduced = selector.transform(X_valid_scaled)\n",
    "\n",
    "X_test_feat = test_df.drop(columns=['id', 'label'], errors='ignore')\n",
    "# Align test columns to train\n",
    "common_cols = list(set(X.columns) & set(X_test_feat.columns))\n",
    "X_test_feat = X_test_feat[common_cols]\n",
    "X_test_scaled = scaler.transform(X_test_feat.values)\n",
    "X_test_reduced = selector.transform(X_test_scaled)\n",
    "\n",
    "mi_scores = mutual_info_regression(X_train_reduced, y_train, random_state=42)\n",
    "mi_mask = mi_scores > np.percentile(mi_scores, 20)\n",
    "X_train_reduced = X_train_reduced[:, mi_mask]\n",
    "X_valid_reduced = X_valid_reduced[:, mi_mask]\n",
    "X_test_reduced = X_test_reduced[:, mi_mask]\n",
    "\n",
    "input_dim = X_train_reduced.shape[1]  # For NN input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a01eae",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea98b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "# Assume your data is already defined and preprocessed:\n",
    "# X_train_reduced, X_valid_reduced, y_train, y_valid\n",
    "input_dim = X_train_reduced.shape[1]\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_units1 = trial.suggest_int('hidden_units1', 64, 256)\n",
    "    hidden_units2 = trial.suggest_int('hidden_units2', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    l2_reg = trial.suggest_float('l2_reg', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Build model with L2 regularization\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units1, input_dim=input_dim, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(hidden_units2, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Callbacks\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    pruning_callback = TFKerasPruningCallback(trial, 'val_loss')\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train_reduced, y_train,\n",
    "                        validation_data=(X_valid_reduced, y_valid),\n",
    "                        epochs=100,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[es, pruning_callback],\n",
    "                        verbose=0)\n",
    "\n",
    "    # Evaluation\n",
    "    preds = model.predict(X_valid_reduced).flatten()\n",
    "\n",
    "    # Pearson correlation (negated because Optuna minimizes)\n",
    "    score = pearsonr(y_valid, preds)[0]\n",
    "    if np.isnan(score):\n",
    "        return float('inf')  # Penalize if Pearson is NaN\n",
    "\n",
    "    return -score\n",
    "\n",
    "# Run the optimization\n",
    "\"\"\" study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=60)\n",
    "\n",
    "# Extract best parameters\n",
    "trial = study.best_trial\n",
    "best_params = trial.params\n",
    "\n",
    "# Output best result\n",
    "print(\"\\nBest Trial:\")\n",
    "print(f\"  Value (negative Pearson): {trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    " \"\"\"\n",
    "best_params = {\n",
    "    'hidden_units1': 237,\n",
    "    'hidden_units2': 40,\n",
    "    'dropout_rate': 0.1025043950801565,\n",
    "    'learning_rate': 5.0006641823893714026e-05,\n",
    "    'batch_size': 32,\n",
    "    'l2_reg': 0.0019536930681741563\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69daf2",
   "metadata": {},
   "source": [
    "## Optuna gave these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00ad00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.6246 - mae: 0.7601 - val_loss: 1.5889 - val_mae: 0.7501\n",
      "Epoch 2/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 1.0242 - mae: 0.5429 - val_loss: 1.6231 - val_mae: 0.7569\n",
      "Epoch 3/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.8729 - mae: 0.4883 - val_loss: 1.6929 - val_mae: 0.7830\n",
      "Epoch 4/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.7648 - mae: 0.4459 - val_loss: 1.6560 - val_mae: 0.7780\n",
      "Epoch 5/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6953 - mae: 0.4168 - val_loss: 1.6953 - val_mae: 0.7938\n",
      "Epoch 6/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6499 - mae: 0.3959 - val_loss: 1.7302 - val_mae: 0.8136\n",
      "Epoch 7/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6039 - mae: 0.3770 - val_loss: 1.7072 - val_mae: 0.8095\n",
      "Epoch 8/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.5716 - mae: 0.3624 - val_loss: 1.7015 - val_mae: 0.8105\n",
      "Epoch 9/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.5403 - mae: 0.3496 - val_loss: 1.7282 - val_mae: 0.8248\n",
      "Epoch 10/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.5131 - mae: 0.3380 - val_loss: 1.6903 - val_mae: 0.8193\n",
      "Epoch 11/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.4877 - mae: 0.3284 - val_loss: 1.7159 - val_mae: 0.8352\n",
      "Epoch 12/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.4640 - mae: 0.3185 - val_loss: 1.6979 - val_mae: 0.8313\n",
      "Epoch 13/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.4502 - mae: 0.3143 - val_loss: 1.7133 - val_mae: 0.8394\n",
      "Epoch 14/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.4314 - mae: 0.3100 - val_loss: 1.6571 - val_mae: 0.8240\n",
      "Epoch 15/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.4173 - mae: 0.3042 - val_loss: 1.6720 - val_mae: 0.8351\n",
      "Epoch 16/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3996 - mae: 0.2971 - val_loss: 1.6708 - val_mae: 0.8391\n",
      "Epoch 17/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3857 - mae: 0.2927 - val_loss: 1.6581 - val_mae: 0.8336\n",
      "Epoch 18/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3721 - mae: 0.2885 - val_loss: 1.6317 - val_mae: 0.8278\n",
      "Epoch 19/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3591 - mae: 0.2863 - val_loss: 1.6482 - val_mae: 0.8373\n",
      "Epoch 20/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3445 - mae: 0.2789 - val_loss: 1.6569 - val_mae: 0.8452\n",
      "Epoch 21/150\n",
      "\u001b[1m2740/2740\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3343 - mae: 0.2767 - val_loss: 1.6456 - val_mae: 0.8375\n",
      "\u001b[1m2739/2739\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660us/step\n",
      "Epoch 1/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 1.4379 - mae: 0.6892 - val_loss: 1.4843 - val_mae: 0.6406\n",
      "Epoch 2/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.9835 - mae: 0.5387 - val_loss: 1.6067 - val_mae: 0.6941\n",
      "Epoch 3/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.8340 - mae: 0.4874 - val_loss: 1.7051 - val_mae: 0.7291\n",
      "Epoch 4/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.7306 - mae: 0.4481 - val_loss: 1.7570 - val_mae: 0.7595\n",
      "Epoch 5/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.6602 - mae: 0.4230 - val_loss: 1.6960 - val_mae: 0.7427\n",
      "Epoch 6/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.6087 - mae: 0.4044 - val_loss: 1.7114 - val_mae: 0.7480\n",
      "Epoch 7/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.5662 - mae: 0.3886 - val_loss: 1.6968 - val_mae: 0.7620\n",
      "Epoch 8/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.5312 - mae: 0.3752 - val_loss: 1.6878 - val_mae: 0.7607\n",
      "Epoch 9/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.5009 - mae: 0.3642 - val_loss: 1.6850 - val_mae: 0.7585\n",
      "Epoch 10/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.4759 - mae: 0.3578 - val_loss: 1.6710 - val_mae: 0.7654\n",
      "Epoch 11/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.4501 - mae: 0.3483 - val_loss: 1.6798 - val_mae: 0.7741\n",
      "Epoch 12/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.4285 - mae: 0.3428 - val_loss: 1.6671 - val_mae: 0.7723\n",
      "Epoch 13/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.4098 - mae: 0.3368 - val_loss: 1.7276 - val_mae: 0.7927\n",
      "Epoch 14/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3934 - mae: 0.3316 - val_loss: 1.6830 - val_mae: 0.7825\n",
      "Epoch 15/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3767 - mae: 0.3265 - val_loss: 1.7302 - val_mae: 0.8007\n",
      "Epoch 16/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.3620 - mae: 0.3219 - val_loss: 1.6396 - val_mae: 0.7762\n",
      "Epoch 17/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3481 - mae: 0.3186 - val_loss: 1.6462 - val_mae: 0.7718\n",
      "Epoch 18/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3356 - mae: 0.3148 - val_loss: 1.6714 - val_mae: 0.7983\n",
      "Epoch 19/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3249 - mae: 0.3124 - val_loss: 1.6694 - val_mae: 0.7883\n",
      "Epoch 20/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3127 - mae: 0.3079 - val_loss: 1.5968 - val_mae: 0.7828\n",
      "Epoch 21/150\n",
      "\u001b[1m5479/5479\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.3073 - mae: 0.3077 - val_loss: 1.6806 - val_mae: 0.8058\n",
      "\u001b[1m2739/2739\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step\n",
      "Epoch 1/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 1.4468 - mae: 0.6719 - val_loss: 1.5086 - val_mae: 0.6555\n",
      "Epoch 2/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 1.0002 - mae: 0.5361 - val_loss: 1.5604 - val_mae: 0.6813\n",
      "Epoch 3/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.8463 - mae: 0.4925 - val_loss: 1.5874 - val_mae: 0.7076\n",
      "Epoch 4/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.7401 - mae: 0.4589 - val_loss: 1.5946 - val_mae: 0.7222\n",
      "Epoch 5/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.6653 - mae: 0.4360 - val_loss: 1.6037 - val_mae: 0.7229\n",
      "Epoch 6/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.6111 - mae: 0.4196 - val_loss: 1.6940 - val_mae: 0.7528\n",
      "Epoch 7/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.5666 - mae: 0.4051 - val_loss: 1.5894 - val_mae: 0.7368\n",
      "Epoch 8/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.5264 - mae: 0.3919 - val_loss: 1.6348 - val_mae: 0.7559\n",
      "Epoch 9/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.4971 - mae: 0.3820 - val_loss: 1.6360 - val_mae: 0.7531\n",
      "Epoch 10/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.4690 - mae: 0.3739 - val_loss: 1.6541 - val_mae: 0.7679\n",
      "Epoch 11/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.4422 - mae: 0.3656 - val_loss: 1.6772 - val_mae: 0.7783\n",
      "Epoch 12/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.4255 - mae: 0.3607 - val_loss: 1.7322 - val_mae: 0.7818\n",
      "Epoch 13/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.4039 - mae: 0.3531 - val_loss: 1.6949 - val_mae: 0.7848\n",
      "Epoch 14/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.3910 - mae: 0.3503 - val_loss: 1.7475 - val_mae: 0.7922\n",
      "Epoch 15/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.3733 - mae: 0.3447 - val_loss: 1.8295 - val_mae: 0.8070\n",
      "Epoch 16/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.3587 - mae: 0.3398 - val_loss: 1.6873 - val_mae: 0.7890\n",
      "Epoch 17/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.3461 - mae: 0.3350 - val_loss: 1.7284 - val_mae: 0.8006\n",
      "Epoch 18/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.3350 - mae: 0.3305 - val_loss: 1.7311 - val_mae: 0.8063\n",
      "Epoch 19/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.3243 - mae: 0.3287 - val_loss: 1.7820 - val_mae: 0.8158\n",
      "Epoch 20/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.3180 - mae: 0.3256 - val_loss: 1.7701 - val_mae: 0.8028\n",
      "Epoch 21/150\n",
      "\u001b[1m8218/8218\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.3075 - mae: 0.3234 - val_loss: 1.7659 - val_mae: 0.7899\n",
      "\u001b[1m2739/2739\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step\n",
      "Epoch 1/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 1.4761 - mae: 0.6745 - val_loss: 1.4691 - val_mae: 0.7431\n",
      "Epoch 2/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 1.0414 - mae: 0.5492 - val_loss: 1.4752 - val_mae: 0.7573\n",
      "Epoch 3/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.8726 - mae: 0.5073 - val_loss: 1.5527 - val_mae: 0.7987\n",
      "Epoch 4/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.7717 - mae: 0.4790 - val_loss: 1.6382 - val_mae: 0.8398\n",
      "Epoch 5/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.6921 - mae: 0.4563 - val_loss: 1.5883 - val_mae: 0.8274\n",
      "Epoch 6/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.6359 - mae: 0.4396 - val_loss: 1.5748 - val_mae: 0.8233\n",
      "Epoch 7/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.5861 - mae: 0.4244 - val_loss: 1.5971 - val_mae: 0.8388\n",
      "Epoch 8/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.5469 - mae: 0.4128 - val_loss: 1.6903 - val_mae: 0.8701\n",
      "Epoch 9/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.5104 - mae: 0.4021 - val_loss: 1.7432 - val_mae: 0.8876\n",
      "Epoch 10/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.4831 - mae: 0.3939 - val_loss: 1.6567 - val_mae: 0.8625\n",
      "Epoch 11/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.4603 - mae: 0.3869 - val_loss: 1.6315 - val_mae: 0.8657\n",
      "Epoch 12/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.4374 - mae: 0.3791 - val_loss: 1.6018 - val_mae: 0.8608\n",
      "Epoch 13/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.4166 - mae: 0.3737 - val_loss: 1.6889 - val_mae: 0.8783\n",
      "Epoch 14/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.3990 - mae: 0.3681 - val_loss: 1.6355 - val_mae: 0.8821\n",
      "Epoch 15/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.3845 - mae: 0.3627 - val_loss: 1.6456 - val_mae: 0.8833\n",
      "Epoch 16/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.3709 - mae: 0.3574 - val_loss: 1.7197 - val_mae: 0.9041\n",
      "Epoch 17/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.3624 - mae: 0.3554 - val_loss: 1.6540 - val_mae: 0.8890\n",
      "Epoch 18/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.3487 - mae: 0.3509 - val_loss: 1.6630 - val_mae: 0.8905\n",
      "Epoch 19/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.3381 - mae: 0.3472 - val_loss: 1.7283 - val_mae: 0.9103\n",
      "Epoch 20/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.3298 - mae: 0.3443 - val_loss: 1.7658 - val_mae: 0.9292\n",
      "Epoch 21/150\n",
      "\u001b[1m10956/10956\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.3207 - mae: 0.3408 - val_loss: 1.6668 - val_mae: 0.8997\n",
      "\u001b[1m2739/2739\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step\n",
      "Epoch 1/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 1.4341 - mae: 0.6750 - val_loss: 2.1427 - val_mae: 0.8803\n",
      "Epoch 2/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 1.0207 - mae: 0.5565 - val_loss: 2.4929 - val_mae: 0.9633\n",
      "Epoch 3/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.8513 - mae: 0.5130 - val_loss: 2.7012 - val_mae: 1.0001\n",
      "Epoch 4/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.7433 - mae: 0.4847 - val_loss: 3.0223 - val_mae: 1.0804\n",
      "Epoch 5/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.6709 - mae: 0.4637 - val_loss: 3.3027 - val_mae: 1.0998\n",
      "Epoch 6/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.6189 - mae: 0.4490 - val_loss: 3.6717 - val_mae: 1.1445\n",
      "Epoch 7/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.5756 - mae: 0.4367 - val_loss: 3.9993 - val_mae: 1.1761\n",
      "Epoch 8/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.5392 - mae: 0.4247 - val_loss: 3.9445 - val_mae: 1.2161\n",
      "Epoch 9/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.5027 - mae: 0.4149 - val_loss: 4.1026 - val_mae: 1.2067\n",
      "Epoch 10/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.4758 - mae: 0.4070 - val_loss: 4.0344 - val_mae: 1.2124\n",
      "Epoch 11/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.4550 - mae: 0.4002 - val_loss: 4.0826 - val_mae: 1.1990\n",
      "Epoch 12/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.4320 - mae: 0.3935 - val_loss: 4.0417 - val_mae: 1.1741\n",
      "Epoch 13/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.4195 - mae: 0.3894 - val_loss: 3.8038 - val_mae: 1.1848\n",
      "Epoch 14/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.4003 - mae: 0.3824 - val_loss: 4.4177 - val_mae: 1.2131\n",
      "Epoch 15/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.3879 - mae: 0.3791 - val_loss: 4.3526 - val_mae: 1.1906\n",
      "Epoch 16/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.3777 - mae: 0.3747 - val_loss: 4.8354 - val_mae: 1.2376\n",
      "Epoch 17/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.3665 - mae: 0.3715 - val_loss: 4.9789 - val_mae: 1.2920\n",
      "Epoch 18/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.3565 - mae: 0.3679 - val_loss: 4.5261 - val_mae: 1.2332\n",
      "Epoch 19/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.3467 - mae: 0.3636 - val_loss: 5.2851 - val_mae: 1.2662\n",
      "Epoch 20/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 0.3368 - mae: 0.3602 - val_loss: 4.8862 - val_mae: 1.2710\n",
      "Epoch 21/150\n",
      "\u001b[1m13695/13695\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.3269 - mae: 0.3556 - val_loss: 4.5016 - val_mae: 1.2399\n",
      "\u001b[1m2739/2739\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step\n",
      "CV Pearson Scores: [0.07696629330344541, 0.11681556834770027, 0.11117597620257962, 0.10078775539468907, 0.012980845147844637]\n",
      "Mean CV Pearson: 0.08374528767925181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)  # Force TimeSeriesSplit, increased splits\n",
    "\n",
    "#mre effective\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, valid_idx in cv.split(X):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Preprocessing per fold to avoid mismatch\n",
    "    scaler_fold = StandardScaler()\n",
    "    X_tr_scaled = scaler_fold.fit_transform(X_tr)\n",
    "    selector_fold = VarianceThreshold(threshold=1e-4)\n",
    "    X_tr_reduced = selector_fold.fit_transform(X_tr_scaled)\n",
    "    \n",
    "    X_val_scaled = scaler_fold.transform(X_val)\n",
    "    X_val_reduced = selector_fold.transform(X_val_scaled)\n",
    "    \n",
    "    # MI per fold to match dimensions\n",
    "    mi_scores_fold = mutual_info_regression(X_tr_reduced, y_tr, random_state=42)\n",
    "    mi_mask_fold = mi_scores_fold > np.percentile(mi_scores_fold, 20)\n",
    "    X_tr_reduced = X_tr_reduced[:, mi_mask_fold]\n",
    "    X_val_reduced = X_val_reduced[:, mi_mask_fold]\n",
    "    \n",
    "    # Build and fit NN\n",
    "    model = Sequential()\n",
    "    model.add(GaussianNoise(0.01))\n",
    "    model.add(Dense(best_params['hidden_units1'], input_dim=X_tr_reduced.shape[1], activation='swish', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(best_params['dropout_rate']))\n",
    "    model.add(Dense(best_params['hidden_units2'], activation='swish', kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(best_params['dropout_rate']))\n",
    "    model.add(Dense(32, activation='swish', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        weight_decay=0.001    \n",
    "        )\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model.fit(X_tr_reduced, y_tr, validation_data=(X_val_reduced, y_val),\n",
    "              epochs=150, batch_size=best_params['batch_size'], callbacks=[es], verbose=1)\n",
    "    \n",
    "    preds = model.predict(X_val_reduced).flatten()\n",
    "    corr = pearsonr(y_val, preds)[0]\n",
    "    cv_scores.append(corr)\n",
    "    \n",
    "\n",
    "print(\"CV Pearson Scores:\", cv_scores)\n",
    "print(\"Mean CV Pearson:\", np.mean(cv_scores))\n",
    "## Cross-validation with optimised Params\n",
    "X_full_scaled = scaler.fit_transform(X)\n",
    "X_full_reduced = selector.transform(X_full_scaled)[:, mi_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022a6f0",
   "metadata": {},
   "source": [
    "## Cross-validation with optimised Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 1.5163 - mae: 0.6952\n",
      "Epoch 2/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 1.1485 - mae: 0.6378\n",
      "Epoch 3/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 1.0586 - mae: 0.6257\n",
      "Epoch 4/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.9939 - mae: 0.6148\n",
      "Epoch 5/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.9290 - mae: 0.6003\n",
      "Epoch 6/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.8924 - mae: 0.5917\n",
      "Epoch 7/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.8403 - mae: 0.5771\n",
      "Epoch 8/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.8062 - mae: 0.5674\n",
      "Epoch 9/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7733 - mae: 0.5569\n",
      "Epoch 10/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.7468 - mae: 0.5493\n",
      "Epoch 11/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7212 - mae: 0.5396\n",
      "Epoch 12/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6986 - mae: 0.5319\n",
      "Epoch 13/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6824 - mae: 0.5260\n",
      "Epoch 14/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6662 - mae: 0.5180\n",
      "Epoch 15/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6499 - mae: 0.5123\n",
      "Epoch 16/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6343 - mae: 0.5060\n",
      "Epoch 17/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6207 - mae: 0.5013\n",
      "Epoch 18/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6172 - mae: 0.4982\n",
      "Epoch 19/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6016 - mae: 0.4922\n",
      "Epoch 20/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5924 - mae: 0.4893\n",
      "Epoch 21/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5828 - mae: 0.4850\n",
      "Epoch 22/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5763 - mae: 0.4825\n",
      "Epoch 23/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5730 - mae: 0.4789\n",
      "Epoch 24/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5655 - mae: 0.4745\n",
      "Epoch 25/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5586 - mae: 0.4726\n",
      "Epoch 26/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5597 - mae: 0.4723\n",
      "Epoch 27/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5531 - mae: 0.4684\n",
      "Epoch 28/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5432 - mae: 0.4651\n",
      "Epoch 29/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5416 - mae: 0.4641\n",
      "Epoch 30/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5382 - mae: 0.4629\n",
      "Epoch 31/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5323 - mae: 0.4605\n",
      "Epoch 32/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5316 - mae: 0.4592\n",
      "Epoch 33/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5273 - mae: 0.4574\n",
      "Epoch 34/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5239 - mae: 0.4553\n",
      "Epoch 35/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5158 - mae: 0.4530\n",
      "Epoch 36/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5204 - mae: 0.4526\n",
      "Epoch 37/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5119 - mae: 0.4510\n",
      "Epoch 38/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5143 - mae: 0.4502\n",
      "Epoch 39/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5101 - mae: 0.4492\n",
      "Epoch 40/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5044 - mae: 0.4468\n",
      "Epoch 41/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5010 - mae: 0.4462\n",
      "Epoch 42/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5022 - mae: 0.4449\n",
      "Epoch 43/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5074 - mae: 0.4457\n",
      "Epoch 44/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.5075 - mae: 0.4459\n",
      "Epoch 45/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4947 - mae: 0.4421\n",
      "Epoch 46/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4982 - mae: 0.4426\n",
      "Epoch 47/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4932 - mae: 0.4409\n",
      "Epoch 48/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4946 - mae: 0.4404\n",
      "Epoch 49/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4913 - mae: 0.4394\n",
      "Epoch 50/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4952 - mae: 0.4409\n",
      "Epoch 51/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4934 - mae: 0.4397\n",
      "Epoch 52/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4843 - mae: 0.4379\n",
      "Epoch 53/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4897 - mae: 0.4382\n",
      "Epoch 54/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4839 - mae: 0.4362\n",
      "Epoch 55/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4886 - mae: 0.4379\n",
      "Epoch 56/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4853 - mae: 0.4373\n",
      "Epoch 57/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4856 - mae: 0.4369\n",
      "Epoch 58/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4812 - mae: 0.4347\n",
      "Epoch 59/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4813 - mae: 0.4341\n",
      "Epoch 60/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4808 - mae: 0.4334\n",
      "Epoch 61/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4830 - mae: 0.4347\n",
      "Epoch 62/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4837 - mae: 0.4349\n",
      "Epoch 63/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4751 - mae: 0.4321\n",
      "Epoch 64/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4733 - mae: 0.4301\n",
      "Epoch 65/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.4749 - mae: 0.4312\n",
      "Epoch 66/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4750 - mae: 0.4306\n",
      "Epoch 67/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4776 - mae: 0.4312\n",
      "Epoch 68/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4750 - mae: 0.4306\n",
      "Epoch 69/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4730 - mae: 0.4298\n",
      "Epoch 70/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4742 - mae: 0.4305\n",
      "Epoch 71/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4745 - mae: 0.4291\n",
      "Epoch 72/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4676 - mae: 0.4270\n",
      "Epoch 73/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4694 - mae: 0.4279\n",
      "Epoch 74/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4753 - mae: 0.4287\n",
      "Epoch 75/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4712 - mae: 0.4280\n",
      "Epoch 76/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4684 - mae: 0.4276\n",
      "Epoch 77/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4664 - mae: 0.4265\n",
      "Epoch 78/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4702 - mae: 0.4291\n",
      "Epoch 79/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4696 - mae: 0.4263\n",
      "Epoch 80/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4651 - mae: 0.4249\n",
      "Epoch 81/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4576 - mae: 0.4236\n",
      "Epoch 82/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4697 - mae: 0.4271\n",
      "Epoch 83/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4679 - mae: 0.4263\n",
      "Epoch 84/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4599 - mae: 0.4230\n",
      "Epoch 85/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4651 - mae: 0.4255\n",
      "Epoch 86/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4574 - mae: 0.4220\n",
      "Epoch 87/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4635 - mae: 0.4240\n",
      "Epoch 88/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4607 - mae: 0.4229\n",
      "Epoch 89/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4595 - mae: 0.4223\n",
      "Epoch 90/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4587 - mae: 0.4221\n",
      "Epoch 91/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.4601 - mae: 0.4220\n",
      "Epoch 92/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4613 - mae: 0.4218\n",
      "Epoch 93/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4586 - mae: 0.4216\n",
      "Epoch 94/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4550 - mae: 0.4207\n",
      "Epoch 95/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4587 - mae: 0.4218\n",
      "Epoch 96/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4612 - mae: 0.4213\n",
      "Epoch 97/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4557 - mae: 0.4214\n",
      "Epoch 98/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4548 - mae: 0.4200\n",
      "Epoch 99/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4561 - mae: 0.4213\n",
      "Epoch 100/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4550 - mae: 0.4203\n",
      "Epoch 101/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4566 - mae: 0.4203\n",
      "Epoch 102/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4494 - mae: 0.4196\n",
      "Epoch 103/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4556 - mae: 0.4205\n",
      "Epoch 104/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4540 - mae: 0.4209\n",
      "Epoch 105/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4564 - mae: 0.4207\n",
      "Epoch 106/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4528 - mae: 0.4188\n",
      "Epoch 107/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4521 - mae: 0.4185\n",
      "Epoch 108/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4520 - mae: 0.4187\n",
      "Epoch 109/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4535 - mae: 0.4193\n",
      "Epoch 110/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4580 - mae: 0.4205\n",
      "Epoch 111/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4475 - mae: 0.4176\n",
      "Epoch 112/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.4514 - mae: 0.4188\n",
      "Epoch 113/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4492 - mae: 0.4180\n",
      "Epoch 114/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4515 - mae: 0.4171\n",
      "Epoch 115/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4486 - mae: 0.4176\n",
      "Epoch 116/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.4468 - mae: 0.4172\n",
      "Epoch 117/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4455 - mae: 0.4158\n",
      "Epoch 118/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4492 - mae: 0.4173\n",
      "Epoch 119/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4486 - mae: 0.4175\n",
      "Epoch 120/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.4540 - mae: 0.4185\n",
      "Epoch 121/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4496 - mae: 0.4169\n",
      "Epoch 122/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4482 - mae: 0.4169\n",
      "Epoch 123/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4403 - mae: 0.4138\n",
      "Epoch 124/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4491 - mae: 0.4171\n",
      "Epoch 125/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4414 - mae: 0.4147\n",
      "Epoch 126/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4415 - mae: 0.4153\n",
      "Epoch 127/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4478 - mae: 0.4165\n",
      "Epoch 128/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4445 - mae: 0.4150\n",
      "Epoch 129/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4509 - mae: 0.4173\n",
      "Epoch 130/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4364 - mae: 0.4111\n",
      "Epoch 131/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4474 - mae: 0.4162\n",
      "Epoch 132/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4416 - mae: 0.4145\n",
      "Epoch 133/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4468 - mae: 0.4148\n",
      "Epoch 134/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4402 - mae: 0.4133\n",
      "Epoch 135/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4407 - mae: 0.4134\n",
      "Epoch 136/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4448 - mae: 0.4157\n",
      "Epoch 137/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4375 - mae: 0.4115\n",
      "Epoch 138/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4427 - mae: 0.4132\n",
      "Epoch 139/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4413 - mae: 0.4134\n",
      "Epoch 140/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4434 - mae: 0.4147\n",
      "Epoch 141/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4436 - mae: 0.4153\n",
      "Epoch 142/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4436 - mae: 0.4130\n",
      "Epoch 143/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4487 - mae: 0.4142\n",
      "Epoch 144/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4438 - mae: 0.4144\n",
      "Epoch 145/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4373 - mae: 0.4114\n",
      "Epoch 146/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4432 - mae: 0.4135\n",
      "Epoch 147/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4444 - mae: 0.4131\n",
      "Epoch 148/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4391 - mae: 0.4121\n",
      "Epoch 149/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4398 - mae: 0.4118\n",
      "Epoch 150/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.4429 - mae: 0.4138\n",
      "\u001b[1m16818/16818\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 649us/step\n",
      "‚úÖ Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "X_full_scaled = scaler.fit_transform(X)\n",
    "X_full_reduced = selector.transform(X_full_scaled)[:, mi_mask]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.05))\n",
    "model.add(Dense(best_params['hidden_units1'], input_dim=X_full_reduced.shape[1], activation='swish', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(best_params['dropout_rate']))\n",
    "model.add(Dense(best_params['hidden_units2'], activation='swish', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(best_params['dropout_rate']))\n",
    "model.add(Dense(32, activation='swish', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    weight_decay=0.001\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    ")\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "model.fit(X_full_reduced, y, epochs=150, batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "# Predict on Test set\n",
    "test_preds = model.predict(X_test_reduced).flatten()\n",
    "test_preds = np.clip(test_preds, y.quantile(0.01), y.quantile(0.99))\n",
    "\n",
    "# Submission\n",
    "ids = test_df['id'] if 'id' in test_df.columns else range(len(test_preds))\n",
    "submission = pd.DataFrame({\"id\": ids, \"prediction\": test_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ Submission saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c6dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  prediction\n",
      "0   0   -2.765707\n",
      "1   1    3.107727\n",
      "2   2    3.107727\n",
      "3   3    3.107727\n",
      "4   4    3.107727\n",
      "\n",
      " Updated DataFrame:\n",
      "   id  prediction\n",
      "0   1   -2.765706\n",
      "1   2    3.107727\n",
      "2   3    3.107727\n",
      "3   4    3.107727\n",
      "4   5    3.107727\n"
     ]
    }
   ],
   "source": [
    "print(submission.head())\n",
    "df = pd.read_csv('submission.csv')\n",
    "\n",
    "# Increase every value in the first column by one\n",
    "# Assuming the first column is numeric; if it's 'ID', this will increment IDs\n",
    "df.iloc[:, 0] = df.iloc[:, 0] + 1\n",
    "\n",
    "# Save the updated DataFrame (replace 'output_file.csv' with desired name)\n",
    "df.to_csv('updated_s.csv', index=False)\n",
    "\n",
    "print(\"\\n Updated DataFrame:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
