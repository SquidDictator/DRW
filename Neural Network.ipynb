{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a590e7a4",
   "metadata": {},
   "source": [
    "# Crypto Forecasting Kaggle Project – Neural Network Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03748371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GaussianNoise\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "import optuna\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d5958",
   "metadata": {},
   "source": [
    "## Load Data With memory optimisation, and create dtypes for all collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24660cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "float_cols = [col for col in train_df.columns if col.startswith('X') or col == 'label']\n",
    "dtypes = {col: 'float32' for col in float_cols}\n",
    "if 'timestamp' in train_df.columns:\n",
    "    dtypes['timestamp'] = 'int64'\n",
    "if 'asset_id' in train_df.columns:\n",
    "    dtypes['asset_id'] = 'int32'\n",
    "train_df = train_df.astype(dtypes)\n",
    "test_df = pd.read_parquet(\"test.parquet\")\n",
    "test_dtypes = {col: 'float32' for col in test_df.columns if col.startswith('X')}\n",
    "if 'timestamp' in test_df.columns:\n",
    "    test_dtypes['timestamp'] = 'int64'\n",
    "if 'asset_id' in test_df.columns:\n",
    "    test_dtypes['asset_id'] = 'int32'\n",
    "if 'id' in test_df.columns:\n",
    "    test_dtypes['id'] = 'int64'\n",
    "test_df = test_df.astype(test_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1585c",
   "metadata": {},
   "source": [
    "## Handle infinity and NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b85f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_df.fillna(train_df.median(numeric_only=True), inplace=True)\n",
    "test_df.fillna(train_df.median(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71c410",
   "metadata": {},
   "source": [
    "## Split Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f55900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features stats:\n",
      "                X758           X778           X611           X344  \\\n",
      "count  420708.000000  420708.000000  420708.000000  420708.000000   \n",
      "mean        0.002617      -0.003382       0.314378      -0.051555   \n",
      "std         1.034226       1.002533       0.913698       0.851696   \n",
      "min        -2.987701      -0.807793      -4.075869      -4.814550   \n",
      "25%        -0.818695      -0.760120      -0.118007      -0.483976   \n",
      "50%         0.044913      -0.605572       0.268551      -0.144311   \n",
      "75%         0.868943       1.012918       0.667088       0.314403   \n",
      "max         2.544050       1.765409       5.781154       5.227328   \n",
      "\n",
      "                X345           X465           X614           X385  \\\n",
      "count  420708.000000  420708.000000  420708.000000  420708.000000   \n",
      "mean       -0.066188       0.056253       0.018427       0.078397   \n",
      "std         0.978137       0.852683       0.734919       0.779965   \n",
      "min       -14.317780      -6.590180      -2.863041      -3.870314   \n",
      "25%        -0.246405      -0.414525      -0.130318      -0.349436   \n",
      "50%        -0.073520       0.023713      -0.008911       0.009855   \n",
      "75%         0.186982       0.471325       0.128980       0.435222   \n",
      "max         7.835294       4.373323       2.813456       4.376609   \n",
      "\n",
      "                X610           X445           X752           X759  \\\n",
      "count  420708.000000  420708.000000  420708.000000  420708.000000   \n",
      "mean        0.015176      -0.027622      -0.022823      -0.004373   \n",
      "std         1.343083       1.075042       0.997820       0.955801   \n",
      "min       -17.479092      -3.275606      -6.207182     -10.280828   \n",
      "25%        -0.016621      -0.821218      -0.378737      -0.444051   \n",
      "50%         0.010391      -0.041269       0.005786       0.010717   \n",
      "75%         0.032660       0.817639       0.180345       0.422555   \n",
      "max        17.029646       3.200871       6.218754       9.868793   \n",
      "\n",
      "                X444           X757           X751  \n",
      "count  420708.000000  420708.000000  420708.000000  \n",
      "mean       -0.018740      -0.029351       0.044332  \n",
      "std         1.026651       0.943234       1.105651  \n",
      "min        -3.537248      -5.144402     -35.390854  \n",
      "25%        -0.740325      -0.488660      -0.840068  \n",
      "50%        -0.036091      -0.086349      -0.229308  \n",
      "75%         0.724804       0.348938       0.702986  \n",
      "max         3.289459       5.939126       7.426748  \n",
      "\n",
      "Train target stats:\n",
      "count    420708.000000\n",
      "mean          0.037921\n",
      "std           1.009660\n",
      "min         -24.416615\n",
      "25%          -0.379909\n",
      "50%           0.017279\n",
      "75%           0.434756\n",
      "max          20.740271\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Valid features stats:\n",
      "                X758           X778           X611           X344  \\\n",
      "count  105178.000000  105178.000000  105178.000000  105178.000000   \n",
      "mean        0.008330      -0.005792       0.310494      -0.047073   \n",
      "std         1.032781       1.001586       0.911193       0.853046   \n",
      "min        -2.987753      -0.807807      -4.073343      -4.802697   \n",
      "25%        -0.815319      -0.760393      -0.119245      -0.481888   \n",
      "50%         0.049709      -0.607081       0.267764      -0.142351   \n",
      "75%         0.875827       1.004099       0.667183       0.319670   \n",
      "max         2.544205       1.765406       5.776839       5.234836   \n",
      "\n",
      "                X345           X465           X614           X385  \\\n",
      "count  105178.000000  105178.000000  105178.000000  105178.000000   \n",
      "mean       -0.062001       0.056582       0.014834       0.070249   \n",
      "std         0.966996       0.857139       0.743186       0.784773   \n",
      "min       -14.642352      -6.074084      -2.863041      -3.799621   \n",
      "25%        -0.246080      -0.416043      -0.131681      -0.357717   \n",
      "50%        -0.073323       0.023001      -0.008992       0.005078   \n",
      "75%         0.190261       0.472113       0.128131       0.430005   \n",
      "max         7.846313       4.350323       2.813456       4.370514   \n",
      "\n",
      "                X610           X445           X752           X759  \\\n",
      "count  105178.000000  105178.000000  105178.000000  105178.000000   \n",
      "mean        0.006403      -0.025748      -0.027604      -0.004535   \n",
      "std         1.359587       1.076715       1.002938       0.957860   \n",
      "min       -17.503391      -3.264765      -6.207182      -9.866102   \n",
      "25%        -0.016566      -0.819418      -0.386318      -0.449532   \n",
      "50%         0.010541      -0.037935       0.005786       0.010717   \n",
      "75%         0.032660       0.818850       0.171944       0.423401   \n",
      "max        17.006050       3.195662       6.218754       9.882494   \n",
      "\n",
      "                X444           X757           X751  \n",
      "count  105178.000000  105178.000000  105178.000000  \n",
      "mean       -0.018373      -0.034621       0.042911  \n",
      "std         1.027666       0.944855       1.112248  \n",
      "min        -3.527572      -5.038234      -7.917003  \n",
      "25%        -0.739752      -0.493295      -0.840068  \n",
      "50%        -0.033970      -0.088741      -0.228467  \n",
      "75%         0.726122       0.347591       0.704232  \n",
      "max         3.268500       5.991687       7.317129  \n",
      "\n",
      "Valid target stats:\n",
      "count    105178.000000\n",
      "mean          0.028947\n",
      "std           1.010905\n",
      "min         -16.227390\n",
      "25%          -0.388457\n",
      "50%           0.012406\n",
      "75%           0.431602\n",
      "max          11.916870\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Selected features from feature selection\n",
    "selected_features = ['X758','X778','X611','X344','X345','X465',\n",
    "                     'X614','X385','X610','X445','X752','X759',\n",
    "                     'X444','X757','X751']\n",
    "\n",
    "# Prepare training and test features\n",
    "X = train_df[selected_features]\n",
    "y = train_df['label']\n",
    "X_test_feat = test_df[selected_features]\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print basic stats\n",
    "print(\"Train features stats:\")\n",
    "print(X_train.describe())\n",
    "print(\"\\nTrain target stats:\")\n",
    "print(y_train.describe())\n",
    "print(\"\\nValid features stats:\")\n",
    "print(X_valid.describe())\n",
    "print(\"\\nValid target stats:\")\n",
    "print(y_valid.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2f575",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7311173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using RobustScaler (less sensitive to outliers)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_valid_scaled = scaler.transform(X_valid.values)\n",
    "\n",
    "# Optional: Remove near-zero variance features\n",
    "selector = VarianceThreshold(threshold=1e-4)\n",
    "X_train_reduced = selector.fit_transform(X_train_scaled)\n",
    "X_valid_reduced = selector.transform(X_valid_scaled)\n",
    "\n",
    "# Prepare test set\n",
    "X_test_feat = test_df[selected_features]  # only use selected features\n",
    "X_test_scaled = scaler.transform(X_test_feat.values)\n",
    "X_test_reduced = selector.transform(X_test_scaled)\n",
    "\n",
    "# Input dimension for neural network\n",
    "input_dim = X_train_reduced.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a01eae",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea98b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network hyperparameter tuning (Optuna) - commented\n",
    "\"\"\"\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_units1 = trial.suggest_int('hidden_units1', 64, 256)\n",
    "    hidden_units2 = trial.suggest_int('hidden_units2', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    l2_reg = trial.suggest_float('l2_reg', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Build and train model...\n",
    "    # Evaluate with Pearson correlation\n",
    "    return -score\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=60)\n",
    "best_params = study.best_trial.params\n",
    "\"\"\"\n",
    "\n",
    "# Use best parameters from previous tuning\n",
    "best_params = {\n",
    "    'hidden_units1': 237,\n",
    "    'hidden_units2': 40,\n",
    "    'dropout_rate': 0.1025,\n",
    "    'learning_rate': 5e-5,\n",
    "    'batch_size': 32,\n",
    "    'l2_reg': 0.00195\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69daf2",
   "metadata": {},
   "source": [
    "## Building our Neural Network, and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00ad00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on FULL data...\n",
      "Epoch 1/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 1.3821\n",
      "Epoch 2/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 1.1540\n",
      "Epoch 3/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 1.0966\n",
      "Epoch 4/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 1.0484\n",
      "Epoch 5/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 1.0222\n",
      "Epoch 6/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 1.0108\n",
      "Epoch 7/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9755\n",
      "Epoch 8/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9711\n",
      "Epoch 9/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9464\n",
      "Epoch 10/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.9474\n",
      "Epoch 11/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.9413\n",
      "Epoch 12/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.9302\n",
      "Epoch 13/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.9295\n",
      "Epoch 14/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9180\n",
      "Epoch 15/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9074\n",
      "Epoch 16/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.9039\n",
      "Epoch 17/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.9089\n",
      "Epoch 18/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.8980\n",
      "Epoch 19/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.8866\n",
      "Epoch 20/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8800\n",
      "Epoch 21/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.8788\n",
      "Epoch 22/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.8740\n",
      "Epoch 23/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8776\n",
      "Epoch 24/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8575\n",
      "Epoch 25/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8611\n",
      "Epoch 26/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8619\n",
      "Epoch 27/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8472\n",
      "Epoch 28/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8433\n",
      "Epoch 29/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8450\n",
      "Epoch 30/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.8405\n",
      "Epoch 31/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8335\n",
      "Epoch 32/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8363\n",
      "Epoch 33/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8310\n",
      "Epoch 34/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8294\n",
      "Epoch 35/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8158\n",
      "Epoch 36/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8166\n",
      "Epoch 37/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8147\n",
      "Epoch 38/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8143\n",
      "Epoch 39/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8002\n",
      "Epoch 40/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.8037\n",
      "Epoch 41/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.7986\n",
      "Epoch 42/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.8022\n",
      "Epoch 43/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.8037\n",
      "Epoch 44/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.7966\n",
      "Epoch 45/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.7975\n",
      "Epoch 46/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7882\n",
      "Epoch 47/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7840\n",
      "Epoch 48/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7879\n",
      "Epoch 49/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7775\n",
      "Epoch 50/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7781\n",
      "Epoch 51/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7836\n",
      "Epoch 52/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7744\n",
      "Epoch 53/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7748\n",
      "Epoch 54/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7673\n",
      "Epoch 55/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7765\n",
      "Epoch 56/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7642\n",
      "Epoch 57/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7668\n",
      "Epoch 58/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7624\n",
      "Epoch 59/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7555\n",
      "Epoch 60/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7572\n",
      "Epoch 61/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7550\n",
      "Epoch 62/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7530\n",
      "Epoch 63/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7571\n",
      "Epoch 64/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7469\n",
      "Epoch 65/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7406\n",
      "Epoch 66/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.7456\n",
      "Epoch 67/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7451\n",
      "Epoch 68/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7447\n",
      "Epoch 69/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7444\n",
      "Epoch 70/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7418\n",
      "Epoch 71/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7350\n",
      "Epoch 72/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7336\n",
      "Epoch 73/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7352\n",
      "Epoch 74/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.7339\n",
      "Epoch 75/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7378\n",
      "Epoch 76/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7301\n",
      "Epoch 77/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7277\n",
      "Epoch 78/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7277\n",
      "Epoch 79/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7266\n",
      "Epoch 80/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.7222\n",
      "Epoch 81/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7269\n",
      "Epoch 82/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7224\n",
      "Epoch 83/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7231\n",
      "Epoch 84/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7155\n",
      "Epoch 85/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7198\n",
      "Epoch 86/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7257\n",
      "Epoch 87/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7131\n",
      "Epoch 88/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7204\n",
      "Epoch 89/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7157\n",
      "Epoch 90/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7160\n",
      "Epoch 91/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7158\n",
      "Epoch 92/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7173\n",
      "Epoch 93/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7039\n",
      "Epoch 94/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7159\n",
      "Epoch 95/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7149\n",
      "Epoch 96/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.7151\n",
      "Epoch 97/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7085\n",
      "Epoch 98/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7062\n",
      "Epoch 99/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7059\n",
      "Epoch 100/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.7062\n",
      "Epoch 101/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.7051\n",
      "Epoch 102/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.7051\n",
      "Epoch 103/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.6990\n",
      "Epoch 104/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7048\n",
      "Epoch 105/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.7023\n",
      "Epoch 106/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.6964\n",
      "Epoch 107/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.6955\n",
      "Epoch 108/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.6964\n",
      "Epoch 109/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.7050\n",
      "Epoch 110/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.6990\n",
      "Epoch 111/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.6967\n",
      "Epoch 112/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6947\n",
      "Epoch 113/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6951\n",
      "Epoch 114/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6921\n",
      "Epoch 115/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.6913\n",
      "Epoch 116/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 0.6913\n",
      "Epoch 117/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6881\n",
      "Epoch 118/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.6902\n",
      "Epoch 119/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6927\n",
      "Epoch 120/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6830\n",
      "Epoch 121/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6884\n",
      "Epoch 122/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6869\n",
      "Epoch 123/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6845\n",
      "Epoch 124/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6872\n",
      "Epoch 125/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6821\n",
      "Epoch 126/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.6811\n",
      "Epoch 127/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6822\n",
      "Epoch 128/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6811\n",
      "Epoch 129/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6775\n",
      "Epoch 130/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6823\n",
      "Epoch 131/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6787\n",
      "Epoch 132/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6810\n",
      "Epoch 133/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6791\n",
      "Epoch 134/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6779\n",
      "Epoch 135/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6717\n",
      "Epoch 136/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6792\n",
      "Epoch 137/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6756\n",
      "Epoch 138/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6723\n",
      "Epoch 139/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 0.6727\n",
      "Epoch 140/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6732\n",
      "Epoch 141/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6690\n",
      "Epoch 142/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6724\n",
      "Epoch 143/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6709\n",
      "Epoch 144/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6738\n",
      "Epoch 145/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6719\n",
      "Epoch 146/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6656\n",
      "Epoch 147/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.6702\n",
      "Epoch 148/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6715\n",
      "Epoch 149/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.6687\n",
      "Epoch 150/150\n",
      "\u001b[1m16434/16434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.6696\n"
     ]
    }
   ],
   "source": [
    "# Split train into features and target\n",
    "X_full = train_df[selected_features]\n",
    "y_full = train_df['label']\n",
    "X_test = test_df[selected_features]\n",
    "\n",
    "# Fit preprocessing on training data\n",
    "scaler = RobustScaler()\n",
    "X_full_scaled = scaler.fit_transform(X_full.values)\n",
    "\n",
    "selector = VarianceThreshold(threshold=1e-4)\n",
    "X_full_reduced = selector.fit_transform(X_full_scaled)\n",
    "\n",
    "# Transform test set with the same fitted objects\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "X_test_reduced = selector.transform(X_test_scaled)\n",
    "\n",
    "# Build final model\n",
    "model = Sequential([\n",
    "    GaussianNoise(0.01),\n",
    "    Dense(best_params['hidden_units1'], input_dim=X_full_reduced.shape[1],\n",
    "          activation='swish', kernel_regularizer=l2(best_params['l2_reg'])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(best_params['hidden_units2'], activation='swish',\n",
    "          kernel_regularizer=l2(best_params['l2_reg'])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(32, activation='swish', kernel_regularizer=l2(best_params['l2_reg'])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss='mse')\n",
    "\n",
    "print(\"Training final model on FULL data...\")\n",
    "model.fit(X_full_reduced, y_full.values,\n",
    "          epochs=150,\n",
    "          batch_size=best_params['batch_size'],\n",
    "          verbose=1)\n",
    "\n",
    "# Predict + clip\n",
    "preds = model.predict(X_test_reduced, verbose=0).flatten()\n",
    "preds = np.clip(preds, y_full.quantile(0.01), y_full.quantile(0.99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "422ffd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.flatten()\n",                                          
    "submission = pd.DataFrame({\n",
    "    'ID': np.arange(1, len(preds) + 1),     # 1, 2, 3, ..., not 0-based\n",
    "    'prediction': preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
